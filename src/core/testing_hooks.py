"""
AdCP Testing Hooks Implementation

Implements the full AdCP testing specification for comprehensive test backend support:
https://adcontextprotocol.org/docs/media-buy/testing/

This module handles all testing headers and provides isolated test execution:
- X-Dry-Run: Execute without affecting production
- X-Mock-Time: Control simulated time progression
- X-Jump-To-Event: Jump to specific campaign lifecycle events
- X-Test-Session-ID: Isolate test sessions
- X-Auto-Advance: Automatically advance through events
- X-Simulated-Spend: Track simulated spending without real money
"""

from datetime import datetime, timedelta
from enum import Enum
from typing import Any

from fastmcp.server.context import Context
from fastmcp.server.dependencies import get_http_headers
from pydantic import BaseModel

from src.core.tool_context import ToolContext


class CampaignEvent(str, Enum):
    """Campaign lifecycle and error events that can be jumped to."""

    # Lifecycle Events
    CAMPAIGN_CREATION = "campaign-creation"
    CAMPAIGN_PENDING = "campaign-pending"
    CAMPAIGN_APPROVED = "campaign-approved"
    CAMPAIGN_START = "campaign-start"
    CAMPAIGN_MIDPOINT = "campaign-midpoint"
    CAMPAIGN_75_PERCENT = "campaign-75-percent"
    CAMPAIGN_COMPLETE = "campaign-complete"
    CAMPAIGN_PAUSED = "campaign-paused"
    CAMPAIGN_CANCELLED = "campaign-cancelled"

    # Error Events
    CREATIVE_POLICY_VIOLATION = "creative-policy-violation"
    BUDGET_EXCEEDED = "budget-exceeded"
    INVENTORY_UNAVAILABLE = "inventory-unavailable"
    MANUAL_APPROVAL_DELAY = "manual-approval-delay"
    DELIVERY_UNDERPERFORMING = "delivery-underperforming"
    PLATFORM_ERROR = "platform-error"
    TARGETING_CONFLICT = "targeting-conflict"
    CREATIVE_REJECTION = "creative-rejection"


class AdCPTestContext(BaseModel):
    """Context for test execution with all testing hooks."""

    __test__ = False  # Tell pytest not to collect this as a test class

    # Session isolation
    test_session_id: str | None = None

    # Dry run mode
    dry_run: bool = False

    # Time simulation
    mock_time: datetime | None = None
    auto_advance: bool = False

    # Event jumping
    jump_to_event: CampaignEvent | None = None

    # Spend tracking
    simulated_spend: bool = False
    simulated_spend_amount: float = 0.0

    # Advanced testing features
    force_error: str | None = None
    slow_mode: bool = False
    debug_mode: bool = False

    @classmethod
    def from_context(cls, context: Context) -> "TestContext":
        """Extract testing context from FastMCP context headers."""
        if not context:
            return cls()

        # Get headers using the recommended FastMCP approach
        headers = None
        try:
            headers = get_http_headers()
        except Exception:
            pass  # Will try fallback below

        # If get_http_headers() returned empty dict or None, try context.meta fallback
        # This is necessary for sync tools where get_http_headers() may not work
        if not headers:
            if hasattr(context, "meta") and context.meta and "headers" in context.meta:
                headers = context.meta["headers"]
            # Try other possible attributes
            elif hasattr(context, "headers"):
                headers = context.headers
            elif hasattr(context, "_headers"):
                headers = context._headers

        if not headers:
            return cls()  # Return default TestContext if no headers available

        # Extract all testing headers
        test_session_id = headers.get("X-Test-Session-ID")
        dry_run = headers.get("X-Dry-Run", "").lower() == "true"
        auto_advance = headers.get("X-Auto-Advance", "").lower() == "true"
        simulated_spend = headers.get("X-Simulated-Spend", "").lower() == "true"
        force_error = headers.get("X-Force-Error")
        slow_mode = headers.get("X-Slow-Mode", "").lower() == "true"
        debug_mode = headers.get("X-Debug-Mode", "").lower() == "true"

        # Parse mock time
        mock_time = None
        mock_time_header = headers.get("X-Mock-Time")
        if mock_time_header:
            try:
                # Handle both ISO format and timestamp
                if mock_time_header.isdigit():
                    mock_time = datetime.fromtimestamp(int(mock_time_header))
                else:
                    # Remove 'Z' suffix if present and parse
                    time_str = mock_time_header.rstrip("Z")
                    mock_time = datetime.fromisoformat(time_str)
            except (ValueError, OverflowError):
                # Invalid time format, ignore
                pass

        # Parse jump to event
        jump_to_event = None
        jump_event_header = headers.get("X-Jump-To-Event")
        if jump_event_header:
            try:
                jump_to_event = CampaignEvent(jump_event_header)
            except ValueError:
                # Invalid event, ignore
                pass

        return cls(
            test_session_id=test_session_id,
            dry_run=dry_run,
            mock_time=mock_time,
            auto_advance=auto_advance,
            jump_to_event=jump_to_event,
            simulated_spend=simulated_spend,
            force_error=force_error,
            slow_mode=slow_mode,
            debug_mode=debug_mode,
        )


# Backwards compatibility aliases
TestingContext = AdCPTestContext  # Original name
TestContext = AdCPTestContext  # Intermediate name (was briefly used)
TestingHookContext = AdCPTestContext  # Another intermediate name


class NextEventCalculator:
    """Calculates next events and timing for AdCP response headers."""

    @staticmethod
    def get_next_event(
        current_event: CampaignEvent | None, progress: float, testing_ctx: TestContext
    ) -> CampaignEvent | None:
        """Calculate the next expected event in the campaign lifecycle."""

        # If we're jumping to a specific event, the next event depends on what we jumped to
        if testing_ctx.jump_to_event:
            current_event = testing_ctx.jump_to_event

        # Define the normal campaign progression
        lifecycle_progression = [
            CampaignEvent.CAMPAIGN_CREATION,
            CampaignEvent.CAMPAIGN_PENDING,
            CampaignEvent.CAMPAIGN_APPROVED,
            CampaignEvent.CAMPAIGN_START,
            CampaignEvent.CAMPAIGN_MIDPOINT,
            CampaignEvent.CAMPAIGN_75_PERCENT,
            CampaignEvent.CAMPAIGN_COMPLETE,
        ]

        # If no current event specified, determine based on progress
        if not current_event:
            if progress == 0.0:
                current_event = CampaignEvent.CAMPAIGN_CREATION
            elif progress < 0.1:
                current_event = CampaignEvent.CAMPAIGN_START
            elif progress < 0.5:
                current_event = CampaignEvent.CAMPAIGN_START
            elif progress < 0.75:
                current_event = CampaignEvent.CAMPAIGN_MIDPOINT
            elif progress < 1.0:
                current_event = CampaignEvent.CAMPAIGN_75_PERCENT
            else:
                return None  # Campaign complete

        # Find current event in progression and return next
        try:
            current_index = lifecycle_progression.index(current_event)
            if current_index + 1 < len(lifecycle_progression):
                return lifecycle_progression[current_index + 1]
        except ValueError:
            # Current event not in normal progression (error event)
            # Return appropriate next event based on progress
            if progress < 0.5:
                return CampaignEvent.CAMPAIGN_MIDPOINT
            elif progress < 0.75:
                return CampaignEvent.CAMPAIGN_75_PERCENT
            elif progress < 1.0:
                return CampaignEvent.CAMPAIGN_COMPLETE

        return None

    @staticmethod
    def calculate_next_event_time(
        next_event: CampaignEvent, start_date: datetime, end_date: datetime, current_time: datetime | None = None
    ) -> datetime:
        """Calculate when the next event should occur."""
        if current_time is None:
            current_time = datetime.now()

        # Use existing event timing logic
        next_event_time = TimeSimulator.jump_to_event_time(next_event, start_date, end_date)

        # Ensure next event is in the future relative to current time
        if next_event_time <= current_time:
            # Add a small buffer to make it future
            time_buffer = timedelta(minutes=30)
            next_event_time = current_time + time_buffer

        return next_event_time


class SimulatedSpendTracker:
    """Tracks simulated spending across test sessions."""

    def __init__(self) -> None:
        self._session_spend: dict[str, float] = {}

    def update_spend(self, session_id: str, amount: float):
        """Update simulated spend for a session."""
        if session_id:
            self._session_spend[session_id] = amount

    def get_spend(self, session_id: str) -> float:
        """Get current simulated spend for a session."""
        return self._session_spend.get(session_id, 0.0)

    def clear_session(self, session_id: str):
        """Clear spend tracking for a session."""
        if session_id in self._session_spend:
            del self._session_spend[session_id]


class TestSessionManager:
    """Manages isolated test sessions to prevent cross-contamination."""

    def __init__(self) -> None:
        self._sessions: dict[str, dict[str, Any]] = {}
        self._spend_tracker = SimulatedSpendTracker()

    def get_session(self, session_id: str) -> dict[str, Any]:
        """Get or create a test session."""
        if session_id not in self._sessions:
            self._sessions[session_id] = {
                "created_at": datetime.now(),
                "media_buys": {},
                "creatives": {},
                "spend": 0.0,
                "events": [],
                "state": "active",
            }
        return self._sessions[session_id]

    def cleanup_session(self, session_id: str):
        """Clean up a test session."""
        if session_id in self._sessions:
            del self._sessions[session_id]
        self._spend_tracker.clear_session(session_id)

    def update_session_spend(self, session_id: str, amount: float):
        """Update simulated spend for a session."""
        self._spend_tracker.update_spend(session_id, amount)

    def get_session_spend(self, session_id: str) -> float:
        """Get current simulated spend for a session."""
        return self._spend_tracker.get_spend(session_id)

    def list_sessions(self) -> dict[str, Any]:
        """List all active test sessions."""
        return {
            session_id: {
                "created_at": session_data["created_at"],
                "state": session_data["state"],
                "media_buys_count": len(session_data["media_buys"]),
                "total_spend": session_data["spend"],
            }
            for session_id, session_data in self._sessions.items()
        }


class TimeSimulator:
    """Handles time simulation for testing campaigns."""

    @staticmethod
    def calculate_campaign_progress(
        start_date: datetime, end_date: datetime, current_time: datetime | None = None
    ) -> float:
        """Calculate campaign progress as percentage (0.0 to 1.0)."""
        if current_time is None:
            current_time = datetime.now()

        if current_time <= start_date:
            return 0.0
        if current_time >= end_date:
            return 1.0

        total_duration = (end_date - start_date).total_seconds()
        elapsed_duration = (current_time - start_date).total_seconds()

        return min(1.0, max(0.0, elapsed_duration / total_duration))

    @staticmethod
    def jump_to_event_time(event: CampaignEvent, start_date: datetime, end_date: datetime) -> datetime:
        """Calculate the datetime for a specific campaign event."""
        duration = end_date - start_date

        event_times = {
            CampaignEvent.CAMPAIGN_CREATION: start_date - timedelta(days=1),
            CampaignEvent.CAMPAIGN_PENDING: start_date - timedelta(hours=1),
            CampaignEvent.CAMPAIGN_APPROVED: start_date - timedelta(minutes=5),
            CampaignEvent.CAMPAIGN_START: start_date,
            CampaignEvent.CAMPAIGN_MIDPOINT: start_date + duration * 0.5,
            CampaignEvent.CAMPAIGN_75_PERCENT: start_date + duration * 0.75,
            CampaignEvent.CAMPAIGN_COMPLETE: end_date,
            CampaignEvent.CAMPAIGN_PAUSED: start_date + duration * 0.3,
            CampaignEvent.CAMPAIGN_CANCELLED: start_date + duration * 0.2,
            # Error events typically occur during campaign
            CampaignEvent.CREATIVE_POLICY_VIOLATION: start_date + timedelta(hours=2),
            CampaignEvent.BUDGET_EXCEEDED: start_date + duration * 0.8,
            CampaignEvent.INVENTORY_UNAVAILABLE: start_date + timedelta(hours=1),
            CampaignEvent.MANUAL_APPROVAL_DELAY: start_date - timedelta(hours=12),
            CampaignEvent.DELIVERY_UNDERPERFORMING: start_date + duration * 0.4,
            CampaignEvent.PLATFORM_ERROR: start_date + duration * 0.1,
            CampaignEvent.TARGETING_CONFLICT: start_date + timedelta(minutes=30),
            CampaignEvent.CREATIVE_REJECTION: start_date + timedelta(hours=6),
        }

        return event_times.get(event, start_date)


class DeliverySimulator:
    """Simulates realistic campaign delivery based on testing context."""

    @staticmethod
    def calculate_simulated_metrics(budget: float, progress: float, testing_ctx: TestContext) -> dict[str, Any]:
        """Calculate realistic delivery metrics for a campaign."""

        # Base metrics
        impressions_per_dollar = 1000  # Base CPM of $1
        clicks_per_impression = 0.001  # 0.1% CTR
        views_per_impression = 0.7  # 70% viewability

        # Apply event-specific modifications
        if testing_ctx.jump_to_event:
            progress = DeliverySimulator._adjust_progress_for_event(progress, testing_ctx.jump_to_event)

        # Calculate spend based on progress
        spend = budget * progress
        if testing_ctx.simulated_spend:
            spend = min(spend, testing_ctx.simulated_spend_amount or spend)

        # Calculate derived metrics
        impressions = int(spend * impressions_per_dollar)
        clicks = int(impressions * clicks_per_impression)
        video_views = int(impressions * views_per_impression)

        # Error scenarios
        if testing_ctx.force_error:
            return DeliverySimulator._generate_error_scenario(testing_ctx.force_error, spend, impressions)

        # Event-specific adjustments
        status = "active"
        if testing_ctx.jump_to_event:
            status = DeliverySimulator._get_status_for_event(testing_ctx.jump_to_event)

        return {
            "spend": round(spend, 2),
            "impressions": impressions,
            "clicks": clicks,
            "video_views": video_views,
            "ctr": round(clicks / impressions if impressions > 0 else 0, 4),
            "cpm": round(spend / impressions * 1000 if impressions > 0 else 0, 2),
            "viewability_rate": round(views_per_impression, 2),
            "status": status,
            "progress": round(progress, 3),
            "is_simulated": True,
            "test_session_id": testing_ctx.test_session_id,
        }

    @staticmethod
    def _adjust_progress_for_event(progress: float, event: CampaignEvent) -> float:
        """Adjust progress based on jumped-to event."""
        event_progress = {
            CampaignEvent.CAMPAIGN_CREATION: 0.0,
            CampaignEvent.CAMPAIGN_PENDING: 0.0,
            CampaignEvent.CAMPAIGN_APPROVED: 0.0,
            CampaignEvent.CAMPAIGN_START: 0.0,
            CampaignEvent.CAMPAIGN_MIDPOINT: 0.5,
            CampaignEvent.CAMPAIGN_75_PERCENT: 0.75,
            CampaignEvent.CAMPAIGN_COMPLETE: 1.0,
            CampaignEvent.CAMPAIGN_PAUSED: 0.3,
            CampaignEvent.CAMPAIGN_CANCELLED: 0.2,
            CampaignEvent.BUDGET_EXCEEDED: 0.8,
            CampaignEvent.DELIVERY_UNDERPERFORMING: 0.4,
        }
        return event_progress.get(event, progress)

    @staticmethod
    def _get_status_for_event(event: CampaignEvent) -> str:
        """Get campaign status for a specific event."""
        status_map = {
            CampaignEvent.CAMPAIGN_CREATION: "pending",
            CampaignEvent.CAMPAIGN_PENDING: "pending",
            CampaignEvent.CAMPAIGN_APPROVED: "approved",
            CampaignEvent.CAMPAIGN_START: "active",
            CampaignEvent.CAMPAIGN_MIDPOINT: "active",
            CampaignEvent.CAMPAIGN_75_PERCENT: "active",
            CampaignEvent.CAMPAIGN_COMPLETE: "completed",
            CampaignEvent.CAMPAIGN_PAUSED: "paused",
            CampaignEvent.CAMPAIGN_CANCELLED: "cancelled",
            CampaignEvent.BUDGET_EXCEEDED: "paused",
            CampaignEvent.DELIVERY_UNDERPERFORMING: "active",
        }
        return status_map.get(event, "active")

    @staticmethod
    def _generate_error_scenario(error_type: str, spend: float, impressions: int) -> dict[str, Any]:
        """Generate metrics for error scenarios."""
        error_scenarios = {
            "budget_exceeded": {
                "spend": spend * 1.1,  # Over budget
                "impressions": impressions,
                "status": "paused",
                "error": "Budget limit exceeded",
            },
            "low_delivery": {
                "spend": spend * 0.3,  # Under-delivery
                "impressions": int(impressions * 0.3),
                "status": "active",
                "warning": "Delivery below expectations",
            },
            "platform_error": {
                "spend": 0,
                "impressions": 0,
                "status": "error",
                "error": "Platform connectivity issues",
            },
        }

        scenario = error_scenarios.get(error_type, {})
        return {
            "spend": scenario.get("spend", spend),
            "impressions": scenario.get("impressions", impressions),
            "clicks": 0,
            "video_views": 0,
            "ctr": 0,
            "cpm": 0,
            "viewability_rate": 0,
            "status": scenario.get("status", "error"),
            "error": scenario.get("error"),
            "warning": scenario.get("warning"),
            "is_simulated": True,
        }


# Global instances
_session_manager = TestSessionManager()


def get_testing_context(context: Context | ToolContext) -> TestContext:
    """Get testing context from FastMCP context or ToolContext.

    Args:
        context: Either FastMCP Context or ToolContext

    Returns:
        TestContext with testing hooks configuration
    """
    # Handle ToolContext (already has testing_context as dict)
    if isinstance(context, ToolContext):
        if context.testing_context:
            # Convert dict back to TestContext object
            return TestContext(**context.testing_context)
        return TestContext()

    # Handle FastMCP Context (extract from headers)
    return TestContext.from_context(context)


def get_session_manager() -> TestSessionManager:
    """Get the global test session manager."""
    return _session_manager


def get_next_event_calculator() -> type[NextEventCalculator]:
    """Get the next event calculator class."""
    return NextEventCalculator


def is_production_isolated(testing_ctx: TestContext) -> bool:
    """Verify that testing context is properly isolated from production."""
    return testing_ctx.dry_run or testing_ctx.test_session_id is not None or testing_ctx.simulated_spend


def apply_testing_hooks(
    data: dict[str, Any],
    testing_ctx: TestContext,
    operation: str = "unknown",
    campaign_info: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Apply testing hooks to modify operation data/results."""

    # Always mark data as simulated if any testing hooks are active
    if any(
        [
            testing_ctx.dry_run,
            testing_ctx.test_session_id,
            testing_ctx.mock_time,
            testing_ctx.jump_to_event,
            testing_ctx.simulated_spend,
        ]
    ):
        data["is_test"] = True
        data["test_session_id"] = testing_ctx.test_session_id

    # Add dry-run indicators
    if testing_ctx.dry_run:
        data["dry_run"] = True
        if "media_buy_id" in data and not data["media_buy_id"].startswith("test_"):
            data["media_buy_id"] = f"test_{data['media_buy_id']}"

    # Add AdCP testing response headers
    response_headers = {}

    # Calculate progress and next event information
    if campaign_info and any([testing_ctx.auto_advance, testing_ctx.mock_time, testing_ctx.jump_to_event]):
        start_date = campaign_info.get("start_date")
        end_date = campaign_info.get("end_date")
        current_time = testing_ctx.mock_time or datetime.now()

        if start_date and end_date:
            # Calculate current progress
            progress = TimeSimulator.calculate_campaign_progress(start_date, end_date, current_time)

            # Get next event
            current_event = testing_ctx.jump_to_event
            next_event = NextEventCalculator.get_next_event(current_event, progress, testing_ctx)

            if next_event:
                # Add X-Next-Event header
                response_headers["X-Next-Event"] = next_event.value

                # Add X-Next-Event-Time header
                next_event_time = NextEventCalculator.calculate_next_event_time(
                    next_event, start_date, end_date, current_time
                )
                response_headers["X-Next-Event-Time"] = next_event_time.isoformat() + "Z"

    # Add X-Simulated-Spend header
    if testing_ctx.simulated_spend or testing_ctx.test_session_id or testing_ctx.dry_run:
        # Use spend from current response data
        current_spend = data.get("total_spend", 0) or data.get("spend", 0)

        # If no spend in current data, check session tracker
        if current_spend == 0 and testing_ctx.test_session_id:
            session_manager = get_session_manager()
            current_spend = session_manager.get_session_spend(testing_ctx.test_session_id)

        if current_spend > 0:
            response_headers["X-Simulated-Spend"] = f"{current_spend:.2f}"

    # Update session spend tracking
    if testing_ctx.test_session_id and "total_spend" in data:
        session_manager = get_session_manager()
        session_manager.update_session_spend(testing_ctx.test_session_id, data["total_spend"])
    elif testing_ctx.test_session_id and "spend" in data:
        session_manager = get_session_manager()
        session_manager.update_session_spend(testing_ctx.test_session_id, data["spend"])

    # Add response headers to data
    if response_headers:
        data["response_headers"] = response_headers

    # Add debug information if requested
    if testing_ctx.debug_mode:
        data["debug_info"] = {
            "operation": operation,
            "testing_context": testing_ctx.model_dump(),
            "timestamp": datetime.now().isoformat(),
            "response_headers": response_headers,
            "campaign_info": campaign_info,
        }

    return data
